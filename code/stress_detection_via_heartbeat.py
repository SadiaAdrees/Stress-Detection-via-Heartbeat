# -*- coding: utf-8 -*-
"""stress-detection-via-heartbeat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M3Yty-i6a0LpBck4vDzDnDvI80gSh8m4

# ***Driving Insights:“ Stress Detection via Heartbeat Big data  Analytics through RNN ”***

---
*   Sadia Adrees
*   Shaher Bano
*   Izza Zafar
---

## Normal = Not Stress
## Abnormal = Stress

### Libararies Import
"""

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

import tensorflow as tf
from google.colab import drive
drive.mount('/content/drive')

"""**Read DataSet**"""

dfs = [pd.read_csv('/content/drive/MyDrive/Dataset/ptbdb_' + x + '.csv') for x in ['normal', 'abnormal']]

"""List
* 0 = normal
* 1 = Abnormal
"""

#normal
dfs[0]

#abnormal
dfs[1]

#rename the dataframes columns  of both normal and abnormal
for df in dfs:
    df.columns = list(range(len(df.columns)))

dfs[0]

# We concate both the dataframe into one
data = pd.concat(dfs, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
data = data.rename({187: 'Label'}, axis=1)

data

# Display bar chart of heartbeats distribution before training
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.countplot(x='Label', data=data, hue='Label', palette={0: 'blue', 1: 'orange'})
plt.title('Heartbeats Distribution Before Training')
plt.xlabel('Label')
plt.ylabel('Count')
plt.legend(title='Label', labels=['Normal', 'Abnormal'])
plt.show()

"""# Preprocessing"""

y = data['Label'].copy()
X = data.drop('Label', axis=1).copy()

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=1)

X_train

y_train

"""# Training"""

#shape of array  (row , col)
X_train.shape
# tf.expand_dims(X_train , axis=2).shape
# for that we will expand the dimentaions as gru required the input should b 3 dimentional because it accounts for each input being multi being a two dimentional as we have 1d input so we convert it into 3d by expanding it for the given feature

#model train  by RNN

inputs = tf.keras.Input(shape=(X_train.shape[1],))

expand = tf.expand_dims(inputs, axis=2) # expanding it on axis= 2 means 3D
gru = tf.keras.layers.GRU(256, return_sequences=True)(expand)
flatten = tf.keras.layers.Flatten()(gru)

outputs = tf.keras.layers.Dense(1, activation='sigmoid')(flatten)


model = tf.keras.Model(inputs=inputs, outputs=outputs)

#SUMMARY OF THE MODEL
print(model.summary())

#mode optimization regression control to not over fitting
model.compile(
    optimizer='adam',
    loss='binary_crossentropy', # for binary classification problem
    metrics=[
        'accuracy',
        tf.keras.metrics.AUC(name='auc')   # auc is better to understad how each model is doing in each class
    ]
)

    # fit our model in the history
    # because we do not want the training loss completely because most of the time it just over fitting the model
history = model.fit (
    X_train,
    y_train,
    validation_split=0.2,
    batch_size=32,
    epochs=100,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(  # early stoping allow us to monitor a given  value for validation
            monitor='val_loss',
            patience=5,  # we will wait for 5 epochs if it not validating else we gonna stop the training and restore the weight from the best epoch
            restore_best_weights=True
        )
    ]
)

"""# Results"""

results = model.evaluate(X_test, y_test, verbose=0)

print("Test Accuracy: {:.2f}%".format(results[1] * 100))
print("     Test AUC: {:.4f}".format(results[2]))

"""## Test the model"""

y_pred = model.predict(X_test)

y_pred

y_pred_binary = (y_pred > 0.5).astype(int)

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Assuming 'Label' column has values 0 and 1
label_mapping = {0: 'Normal', 1: 'Abnormal'}

# Convert NumPy array to Pandas Series
y_pred_series = pd.Series(y_pred_binary.flatten())

# Create a new column named 'Predicted_Label_Text'
data['Predicted_Label_Text'] = y_pred_series.map(label_mapping)

# Convert to string and handle NaN values
data['Predicted_Label_Text'] = data['Predicted_Label_Text'].astype('str')

# Convert 'Predicted_Label_Text' to categorical with correct order
data['Predicted_Label_Text'] = pd.Categorical(data['Predicted_Label_Text'], categories=['Normal', 'Abnormal'], ordered=True)

# Bar chart of heartbeats distribution after training
plt.figure(figsize=(10, 6))

# Use 'hue_order' to ensure consistent order in the legend
sns.countplot(x='Predicted_Label_Text', data=data, hue='Predicted_Label_Text')

plt.title('Heartbeats Distribution After Training')
plt.xlabel('Predicted Label')
plt.ylabel('Count')
plt.legend(title='Predicted Label')
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Assuming y_pred contains the model predictions
# Assuming X_test contains the test data

# Calculate prediction scores
y_pred_scores = model.predict(X_test)

# Assuming y_pred_binary contains the binary predictions
y_pred_binary = (y_pred_scores > 0.5).astype(int)

# Extract indices where the predicted label is 'Normal'
normal_indices = np.where(y_pred_binary == 0)[0]

# Create a heatmap using seaborn
plt.figure(figsize=(15, 5))
sns.heatmap(y_pred_scores.T, cmap="coolwarm", annot=True, fmt=".2f", xticklabels=1, yticklabels=False)
plt.scatter(normal_indices, [0] * len(normal_indices), color='red', marker='x', label='Predicted Normal')
plt.axhline(0, color='black', linestyle='--', linewidth=2, label='Threshold')
plt.title('Model Prediction Scores for Heartbeats')
plt.xlabel('Data Point Index')
plt.ylabel('Prediction Score')
plt.legend()
plt.show()

"""## Classification Report"""

y_test.unique() #random

from sklearn.utils.multiclass import unique_labels
unique_labels(y_test) # lower to higher >> sort

from sklearn.metrics import classification_report, confusion_matrix

print("Classification Report:")
print(classification_report(y_test, y_pred_binary))

"""# Confusion Matrix"""

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_binary))

import seaborn as sns
import matplotlib.pyplot as plt


# Assuming you have already obtained y_pred_binary and y_test
# Replace these variables with your actual predictions and true labels

# Define class names
class_names = ['Normal', 'Abnormal']

# Calculate the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_binary)

# Create a heatmap using seaborn
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False, xticklabels=class_names, yticklabels=class_names)

# Add labels and title
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")

# Show the plot
plt.show()